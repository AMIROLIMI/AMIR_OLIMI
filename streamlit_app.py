import streamlit as st
import pandas as pd
import numpy as np
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense
from sklearn.preprocessing import MinMaxScaler
import matplotlib.pyplot as plt
from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error, r2_score
import joblib

st.set_page_config(page_title="–ü—Ä–æ–≥–Ω–æ–∑ —Ü–µ–Ω—ã –∑–æ–ª–æ—Ç–∞", layout="wide")
st.title("üìâ –ü—Ä–æ–≥–Ω–æ–∑ —Ü–µ–Ω—ã –∑–æ–ª–æ—Ç—ã—Ö —Å–ª–∏—Ç–∫–æ–≤ —Å –ø–æ–º–æ—â—å—é LSTM")

st.markdown("""
–ú–æ–¥–µ–ª—å –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ—Ç —Ü–µ–Ω—É –∑–æ–ª–æ—Ç–∞ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –Ω–µ–π—Ä–æ—Å–µ—Ç–∏ LSTM.  
–û–±—É—á–µ–Ω–∞ –Ω–∞ 2861 —Ç–æ—á–∫–µ —Å –æ–∫–Ω–æ–º –≤ 14 –¥–Ω–µ–π.  
–ú–µ—Ç—Ä–∏–∫–∏:  
- **RMSE**: 47.33  
- **MAPE**: 0.007  
- **R¬≤**: 0.99  
""")

@st.cache_resource
def load_model():
    model = Sequential([LSTM(32, input_shape=(14, 1)), Dense(1)])
    model.load_weights("lstm_model.weights.h5")
    return model

@st.cache_resource
def load_scaler():
    return joblib.load("scaler.pkl")

def create_dataset(data, window=14):
    X, y = [], []
    for i in range(len(data) - window):
        X.append(data[i:i + window])
        y.append(data[i + window])
    return np.array(X), np.array(y)

def calculate_metrics(y_true, y_pred):
    rmse = np.sqrt(mean_squared_error(y_true, y_pred))
    mape = mean_absolute_percentage_error(y_true, y_pred)
    r2 = r2_score(y_true, y_pred)
    return rmse, mape, r2

def plot_predictions(y_true, y_pred):
    fig, ax = plt.subplots(figsize=(12, 5))
    ax.plot(y_true, label="–ò—Å—Ç–∏–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è", linewidth=2)
    ax.plot(y_pred, label="–ü—Ä–æ–≥–Ω–æ–∑ (LSTM)", linestyle='--')
    ax.set_title("–ü—Ä–æ–≥–Ω–æ–∑ LSTM vs –†–µ–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ")
    ax.set_xlabel("–î–Ω–∏")
    ax.set_ylabel("–¶–µ–Ω–∞")
    ax.legend()
    ax.grid(True)
    return fig

model = load_model()
scaler = load_scaler()

uploaded_file = st.file_uploader("üìÇ –ó–∞–≥—Ä—É–∑–∏—Ç–µ CSV –∏–ª–∏ Excel —Å –∏—Å—Ç–æ—Ä–∏–µ–π —Ü–µ–Ω", type=["csv", "xlsx"])
st.markdown("""
–ï—Å–ª–∏ —É –≤–∞—Å –Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö, –≤—ã –º–æ–∂–µ—Ç–µ —Å–∫–∞—á–∞—Ç—å –∏—Ö –∏–∑ –º–æ–µ–≥–æ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è:  
[AMIROLIMI/AMIR_OLIMI](https://github.com/AMIROLIMI/AMIR_OLIMI)
""")

if uploaded_file:
    df = pd.read_excel(uploaded_file) if uploaded_file.name.endswith("xlsx") else pd.read_csv(uploaded_file)
    df.columns = ['date', 'price']
    df['date'] = pd.to_datetime(df['date'])
    df = df.set_index('date').sort_index()
    st.write(df.tail())

    price_array = df[['price']].values

    try:
        scaled = scaler.transform(price_array)
        min_range, max_range = scaler.data_min_[0], scaler.data_max_[0]
        if price_array.min() < min_range or price_array.max() > max_range:
            st.warning(f"‚ö†Ô∏è –ó–Ω–∞—á–µ–Ω–∏—è –≤—ã—Ö–æ–¥—è—Ç –∑–∞ –¥–∏–∞–ø–∞–∑–æ–Ω –æ–±—É—á–µ–Ω–∏—è —Å–∫–∞–ª–µ—Ä–∞: [{min_range:.2f}, {max_range:.2f}]. "
                       f"–ü—Ä–æ–≥–Ω–æ–∑ –º–æ–∂–µ—Ç –±—ã—Ç—å –∏—Å–∫–∞–∂—ë–Ω.")
    except Exception as e:
        st.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–∏: {e}")
        st.stop()

    X, y = create_dataset(scaled, window=14)
    if len(X) == 0:
        st.warning("–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏—è –æ–∫–æ–Ω.")
        st.stop()

    X = X.reshape((X.shape[0], X.shape[1], 1))

    if st.button("–°–¥–µ–ª–∞—Ç—å –ø—Ä–æ–≥–Ω–æ–∑"):
        y_pred = model.predict(X)
        y_pred_inv = scaler.inverse_transform(y_pred)
        y_true_inv = scaler.inverse_transform(y.reshape(-1, 1))

        rmse, mape, r2 = calculate_metrics(y_true_inv, y_pred_inv)
        st.success(f"üìå RMSE: {rmse:.2f} | MAPE: {mape:.3f} | R¬≤: {r2:.2f}")
        st.pyplot(plot_predictions(y_true_inv, y_pred_inv))
else:
    st.info("–ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –ø—Ä–æ–≥–Ω–æ–∑–∞.")

# import streamlit as st
# import pandas as pd
# import numpy as np
# from tensorflow.keras.models import Sequential
# from tensorflow.keras.layers import LSTM, Dense
# from sklearn.preprocessing import MinMaxScaler
# import matplotlib.pyplot as plt
# from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error, r2_score
# import os
# import joblib

# st.set_page_config(page_title="–ü—Ä–æ–≥–Ω–æ–∑ —Ü–µ–Ω—ã –∑–æ–ª–æ—Ç–∞", layout="wide")
# st.title("–ü—Ä–æ–≥–Ω–æ–∑ —Ü–µ–Ω—ã –∑–æ–ª–æ—Ç—ã—Ö —Å–ª–∏—Ç–∫–æ–≤ —Å –ø–æ–º–æ—â—å—é LSTM")

# st.markdown("""
# –ú–æ–¥–µ–ª—å –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ—Ç —Ü–µ–Ω—É –∑–æ–ª–æ—Ç–∞ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –Ω–µ–π—Ä–æ—Å–µ—Ç–∏ LSTM.  
# –û–±—É—á–µ–Ω–∞ –Ω–∞ 2861 —Ç–æ—á–∫–µ —Å –æ–∫–Ω–æ–º –≤ 14 –¥–Ω–µ–π.  
# –ú–µ—Ç—Ä–∏–∫–∏:  
# - **RMSE**: 47.33  
# - **MAPE**: 0.007  
# - **R¬≤**: 0.99  
# –ö—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—è:  
# - **RMSE**: 53.05  
# - **MAPE**: 0.01  
# - **R¬≤**: 0.90  
# """)

# scaler = joblib.load("scaler.pkl")

# def load_lstm_model():
#     model = Sequential([LSTM(32, input_shape=(14, 1)), Dense(1)])
#     model.load_weights("lstm_model.weights.h5") 
#     return model

# def create_dataset(data, window=14):
#     X, y = [], []
#     for i in range(len(data) - window):
#         X.append(data[i:i+window])
#         y.append(data[i + window])
#     return np.array(X), np.array(y)

# def calculate_metrics(y_true, y_pred):
#     rmse = np.sqrt(mean_squared_error(y_true, (y_pred)))
#     mape = mean_absolute_percentage_error(y_true, (y_pred))
#     r2 = r2_score(y_true, (y_pred))
#     return rmse, mape, r2

# def plot_predictions(y_true, y_pred):
#     fig, ax = plt.subplots(figsize=(12, 5))
#     ax.plot(y_true, label="–ò—Å—Ç–∏–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è", linewidth=2)
#     ax.plot(y_pred, label="–ü—Ä–æ–≥–Ω–æ–∑ (LSTM)", linestyle='--')
#     ax.set_title("–ü—Ä–æ–≥–Ω–æ–∑ LSTM vs –†–µ–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ")
#     ax.set_xlabel("–î–Ω–∏")
#     ax.set_ylabel("–¶–µ–Ω–∞")
#     ax.legend()
#     ax.grid(True)
#     return fig


# model = load_lstm_model()
# uploaded_file = st.file_uploader("üìÇ –ó–∞–≥—Ä—É–∑–∏—Ç–µ CSV –∏–ª–∏ Excel —Å —Ü–µ–Ω–∞–º–∏", type=["csv", "xlsx"])
# st.markdown("""
# –ï—Å–ª–∏ —É –≤–∞—Å –Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö, –≤—ã –º–æ–∂–µ—Ç–µ —Å–∫–∞—á–∞—Ç—å –∏—Ö –∏–∑ –º–æ–µ–≥–æ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è  
# [AMIROLIMI/AMIR_OLIMI](https://github.com/AMIROLIMI/AMIR_OLIMI).
# """
# )

# st.subheader("üìà –ü—Ä–æ–≥–Ω–æ–∑ –ø–æ –¥–∞–Ω–Ω—ã–º:")

# if uploaded_file:
#     df = pd.read_excel(uploaded_file) if uploaded_file.name.endswith("xlsx") else pd.read_csv(uploaded_file)
#     df.columns = ['date', 'price']
#     df['date'] = pd.to_datetime(df['date'])
#     df = df.set_index('date').sort_index()
#     st.write(df.tail())

#     try:
#         scaled = scaler.transform(df[['price']])
#     except:
#         st.error("‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–∏. –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —Ñ–æ—Ä–º–∞—Ç 'price' –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π.")
#         st.stop()

#     X, y = create_dataset(scaled)
#     X = X.reshape((X.shape[0], X.shape[1], 1))

#     if model:
#         if st.button("–°–¥–µ–ª–∞—Ç—å –ø—Ä–æ–≥–Ω–æ–∑"):
#             y_pred = model.predict(X)
#             y_pred_inv = scaler.inverse_transform(y_pred)
#             y_true_inv = scaler.inverse_transform(y.reshape(-1, 1))
#             rmse, mape, r2 = calculate_metrics(y_true_inv, y_pred_inv)
#             st.success(f"üìå RMSE: {rmse:.2f} | MAPE: {mape:.3f} | R¬≤: {r2:.2f}")
#             st.pyplot(plot_predictions(y_true_inv, y_pred_inv))
# else:
#     st.info("–ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∞.")
