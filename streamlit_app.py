
import streamlit as st
import pandas as pd
import numpy as np
import joblib
import matplotlib.pyplot as plt
from tensorflow.keras.models import load_model
from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error, r2_score

WINDOW = 14          # –¥–ª–∏–Ω–∞ –æ–∫–Ω–∞, –∫–∞–∫ –≤ –Ω–æ—É—Ç–±—É–∫–µ

st.set_page_config(page_title="–ü—Ä–æ–≥–Ω–æ–∑ —Ü–µ–Ω—ã –∑–æ–ª–æ—Ç–∞", layout="wide")
st.title("üìâ –ü—Ä–æ–≥–Ω–æ–∑ —Ü–µ–Ω—ã –∑–æ–ª–æ—Ç—ã—Ö —Å–ª–∏—Ç–∫–æ–≤ (LSTM)")

# ---------- –∫–µ—à–∏—Ä—É–µ–º –∑–∞–≥—Ä—É–∑–∫—É –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤ ----------
@st.cache_resource
def load_scaler():
    return joblib.load("scaler.pkl")

@st.cache_resource
def load_lstm():
    return load_model("lstm_model.keras", compile=False)   # –¥–ª—è predict –∫–æ–º–ø–∏–ª—è—Ü–∏—è –Ω–µ –Ω—É–∂–Ω–∞

scaler = load_scaler()
model  = load_lstm()

# ---------- —É—Ç–∏–ª–∏—Ç—ã ----------
def create_dataset(arr, win=WINDOW):
    X, y = [], []
    for i in range(len(arr) - win):
        X.append(arr[i:i + win])
        y.append(arr[i + win])
    return np.array(X), np.array(y)

def metrics(y_true, y_pred):
    rmse = np.sqrt(mean_squared_error(y_true, y_pred))
    mape = mean_absolute_percentage_error(y_true, y_pred)
    r2   = r2_score(y_true, y_pred)
    return rmse, mape, r2

def plot_pred(y_true, y_pred):
    fig, ax = plt.subplots(figsize=(12, 5))
    ax.plot(y_true, label="–ò—Å—Ç–∏–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è", linewidth=2)
    ax.plot(y_pred, label="–ü—Ä–æ–≥–Ω–æ–∑ (LSTM)", linestyle="--")
    ax.set_title("–ü—Ä–æ–≥–Ω–æ–∑ LSTM vs –†–µ–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ")
    ax.set_xlabel("–î–Ω–∏")
    ax.set_ylabel("–¶–µ–Ω–∞")
    ax.legend(); ax.grid(True)
    return fig

# ---------- –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å ----------
file = st.file_uploader("üìÇ –ó–∞–≥—Ä—É–∑–∏—Ç–µ CSV –∏–ª–∏ Excel —Å –∫–æ–ª–æ–Ω–∫–∞–º–∏ date,price", type=("csv", "xlsx"))

if file:
    df = pd.read_excel(file) if file.name.endswith("xlsx") else pd.read_csv(file)
    if df.shape[1] != 2:
        st.error("–§–∞–π–ª –¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å –¥–≤–∞ —Å—Ç–æ–ª–±—Ü–∞: date, price"); st.stop()

    df.columns = ["date", "price"]
    df["date"] = pd.to_datetime(df["date"])
    df = df.set_index("date").sort_index()

    st.write("üìÑ –ü—Ä–µ–¥–ø—Ä–æ—Å–º–æ—Ç—Ä –¥–∞–Ω–Ω—ã—Ö:", df.tail())

    # --- –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ —Ç–µ–º –∂–µ scaler ---
    try:
        scaled = scaler.transform(df[["price"]])
    except ValueError as e:
        st.error(f"–û—à–∏–±–∫–∞ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏—è: {e}"); st.stop()

    if scaled.min() < 0 or scaled.max() > 1:
        st.warning("‚ö†Ô∏è –¶–µ–Ω—ã –≤—ã—Ö–æ–¥—è—Ç –∑–∞ –¥–∏–∞–ø–∞–∑–æ–Ω train-–º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏—è. "
                   "–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –º–æ–≥—É—Ç –±—ã—Ç—å –Ω–µ–¥–æ—Å—Ç–æ–≤–µ—Ä–Ω—ã."); st.stop()

    X, y = create_dataset(scaled, WINDOW)
    if len(X) == 0:
        st.warning("–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Å—Ç—Ä–æ–∫ –¥–ª—è –æ–∫–Ω–∞ 14 –¥–Ω–µ–π."); st.stop()

    X = X.reshape((X.shape[0], X.shape[1], 1))

    if st.button("üîÆ –°–¥–µ–ª–∞—Ç—å –ø—Ä–æ–≥–Ω–æ–∑"):
        y_pred = model.predict(X, verbose=0)
        y_pred_inv = scaler.inverse_transform(y_pred)
        y_true_inv = scaler.inverse_transform(y.reshape(-1, 1))

        rmse, mape, r2 = metrics(y_true_inv, y_pred_inv)
        st.success(f"RMSE: {rmse:.2f} | MAPE: {mape:.3f} | R¬≤: {r2:.3f}")
        st.pyplot(plot_pred(y_true_inv, y_pred_inv))
else:
    st.info("–ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –ø—Ä–æ–≥–Ω–æ–∑–∞.")

# import streamlit as st
# import pandas as pd
# import numpy as np
# from tensorflow.keras.models import Sequential
# from tensorflow.keras.layers import LSTM, Dense
# from sklearn.preprocessing import MinMaxScaler
# import matplotlib.pyplot as plt
# from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error, r2_score
# import os
# import joblib

# st.set_page_config(page_title="–ü—Ä–æ–≥–Ω–æ–∑ —Ü–µ–Ω—ã –∑–æ–ª–æ—Ç–∞", layout="wide")
# st.title("–ü—Ä–æ–≥–Ω–æ–∑ —Ü–µ–Ω—ã –∑–æ–ª–æ—Ç—ã—Ö —Å–ª–∏—Ç–∫–æ–≤ —Å –ø–æ–º–æ—â—å—é LSTM")

# st.markdown("""
# –ú–æ–¥–µ–ª—å –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ—Ç —Ü–µ–Ω—É –∑–æ–ª–æ—Ç–∞ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –Ω–µ–π—Ä–æ—Å–µ—Ç–∏ LSTM.  
# –û–±—É—á–µ–Ω–∞ –Ω–∞ 2861 —Ç–æ—á–∫–µ —Å –æ–∫–Ω–æ–º –≤ 14 –¥–Ω–µ–π.  
# –ú–µ—Ç—Ä–∏–∫–∏:  
# - **RMSE**: 47.33  
# - **MAPE**: 0.007  
# - **R¬≤**: 0.99  
# –ö—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—è:  
# - **RMSE**: 53.05  
# - **MAPE**: 0.01  
# - **R¬≤**: 0.90  
# """)

# scaler = joblib.load("scaler.pkl")

# def load_lstm_model():
#     model = Sequential([LSTM(32, input_shape=(14, 1)), Dense(1)])
#     model.load_weights("lstm_model.weights.h5") 
#     return model

# def create_dataset(data, window=14):
#     X, y = [], []
#     for i in range(len(data) - window):
#         X.append(data[i:i+window])
#         y.append(data[i + window])
#     return np.array(X), np.array(y)

# def calculate_metrics(y_true, y_pred):
#     rmse = np.sqrt(mean_squared_error(y_true, (y_pred)))
#     mape = mean_absolute_percentage_error(y_true, (y_pred))
#     r2 = r2_score(y_true, (y_pred))
#     return rmse, mape, r2

# def plot_predictions(y_true, y_pred):
#     fig, ax = plt.subplots(figsize=(12, 5))
#     ax.plot(y_true, label="–ò—Å—Ç–∏–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è", linewidth=2)
#     ax.plot(y_pred, label="–ü—Ä–æ–≥–Ω–æ–∑ (LSTM)", linestyle='--')
#     ax.set_title("–ü—Ä–æ–≥–Ω–æ–∑ LSTM vs –†–µ–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ")
#     ax.set_xlabel("–î–Ω–∏")
#     ax.set_ylabel("–¶–µ–Ω–∞")
#     ax.legend()
#     ax.grid(True)
#     return fig


# model = load_lstm_model()
# uploaded_file = st.file_uploader("üìÇ –ó–∞–≥—Ä—É–∑–∏—Ç–µ CSV –∏–ª–∏ Excel —Å —Ü–µ–Ω–∞–º–∏", type=["csv", "xlsx"])
# st.markdown("""
# –ï—Å–ª–∏ —É –≤–∞—Å –Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö, –≤—ã –º–æ–∂–µ—Ç–µ —Å–∫–∞—á–∞—Ç—å –∏—Ö –∏–∑ –º–æ–µ–≥–æ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è  
# [AMIROLIMI/AMIR_OLIMI](https://github.com/AMIROLIMI/AMIR_OLIMI).
# """
# )

# st.subheader("üìà –ü—Ä–æ–≥–Ω–æ–∑ –ø–æ –¥–∞–Ω–Ω—ã–º:")

# if uploaded_file:
#     df = pd.read_excel(uploaded_file) if uploaded_file.name.endswith("xlsx") else pd.read_csv(uploaded_file)
#     df.columns = ['date', 'price']
#     df['date'] = pd.to_datetime(df['date'])
#     df = df.set_index('date').sort_index()
#     st.write(df.tail())

#     try:
#         scaled = scaler.transform(df[['price']])
#     except:
#         st.error("‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–∏. –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —Ñ–æ—Ä–º–∞—Ç 'price' –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π.")
#         st.stop()

#     X, y = create_dataset(scaled)
#     X = X.reshape((X.shape[0], X.shape[1], 1))

#     if model:
#         if st.button("–°–¥–µ–ª–∞—Ç—å –ø—Ä–æ–≥–Ω–æ–∑"):
#             y_pred = model.predict(X)
#             y_pred_inv = scaler.inverse_transform(y_pred)
#             y_true_inv = scaler.inverse_transform(y.reshape(-1, 1))
#             rmse, mape, r2 = calculate_metrics(y_true_inv, y_pred_inv)
#             st.success(f"üìå RMSE: {rmse:.2f} | MAPE: {mape:.3f} | R¬≤: {r2:.2f}")
#             st.pyplot(plot_predictions(y_true_inv, y_pred_inv))
# else:
#     st.info("–ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∞.")
