import streamlit as st
import pandas as pd
import numpy as np
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense
from sklearn.preprocessing import MinMaxScaler
import matplotlib.pyplot as plt
from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error, r2_score
import os
import joblib

st.set_page_config(page_title="–ü—Ä–æ–≥–Ω–æ–∑ —Ü–µ–Ω—ã –∑–æ–ª–æ—Ç–∞", layout="wide")
st.title("üí∞ –ü—Ä–æ–≥–Ω–æ–∑ —Ü–µ–Ω—ã –∑–æ–ª–æ—Ç—ã—Ö —Å–ª–∏—Ç–∫–æ–≤ —Å –ø–æ–º–æ—â—å—é LSTM")

st.markdown("""
–ú–æ–¥–µ–ª—å –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ—Ç —Ü–µ–Ω—É –∑–æ–ª–æ—Ç–∞ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –Ω–µ–π—Ä–æ—Å–µ—Ç–∏ LSTM.  
–û–±—É—á–µ–Ω–∞ –Ω–∞ 2861 —Ç–æ—á–∫–µ —Å –æ–∫–Ω–æ–º –≤ 14 –¥–Ω–µ–π.  
–ú–µ—Ç—Ä–∏–∫–∏:  
- **RMSE**: 47.33  
- **MAPE**: 0.007  
- **R¬≤**: 0.99  
–ö—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—è:  
- **RMSE**: 53.05  
- **MAPE**: 0.01  
- **R¬≤**: 0.90  
""")

# –ó–∞–≥—Ä—É–∂–∞–µ–º scaler –∏–∑ —Ñ–∞–π–ª–∞
if os.path.exists("scaler.pkl"):
    scaler = joblib.load("scaler.pkl")
else:
    st.error("‚ùå –§–∞–π–ª 'scaler.pkl' –Ω–µ –Ω–∞–π–¥–µ–Ω. –ü–æ–ª–æ–∂–∏—Ç–µ –µ–≥–æ —Ä—è–¥–æ–º —Å app.py.")
    st.stop()

# –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å
def load_lstm_model():
    model = Sequential([
        LSTM(32, input_shape=(14, 1), activation='relu'),
        Dense(1)
    ])
    model.compile(optimizer='adam', loss='mse')
    if os.path.exists("lstm_model.weights.h5"):
        model.load_weights("lstm_model.weights.h5")
    else:
        st.error("‚ùå –§–∞–π–ª 'lstm_model.weights.h5' –Ω–µ –Ω–∞–π–¥–µ–Ω.")
        return None
    return model

# –§–æ—Ä–º–∏—Ä—É–µ–º –≤—Ö–æ–¥—ã –¥–ª—è –º–æ–¥–µ–ª–∏
def create_dataset(data, window=14):
    X, y = [], []
    for i in range(len(data) - window):
        X.append(data[i:i+window])
        y.append(data[i + window])
    return np.array(X), np.array(y)

# –ú–µ—Ç—Ä–∏–∫–∏
def calculate_metrics(y_true, y_pred):
    rmse = np.sqrt(mean_squared_error(y_true, (y_pred + 240)))
    mape = mean_absolute_percentage_error(y_true, (y_pred + 240))
    r2 = r2_score(y_true, (y_pred + 240))
    return rmse, mape, r2

# –ì—Ä–∞—Ñ–∏–∫ –ø—Ä–æ–≥–Ω–æ–∑–∞
def plot_predictions(y_true, y_pred):
    fig, ax = plt.subplots(figsize=(12, 5))
    ax.plot(y_true, label="–ò—Å—Ç–∏–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è", linewidth=2)
    ax.plot(y_pred + 240, label="–ü—Ä–æ–≥–Ω–æ–∑ (LSTM)", linestyle='--')
    ax.set_title("–ü—Ä–æ–≥–Ω–æ–∑ LSTM vs –†–µ–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ")
    ax.set_xlabel("–î–Ω–∏")
    ax.set_ylabel("–¶–µ–Ω–∞")
    ax.legend()
    ax.grid(True)
    return fig

# –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å
model = load_lstm_model()

# –ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–∞
uploaded_file = st.file_uploader("üìÇ –ó–∞–≥—Ä—É–∑–∏—Ç–µ CSV –∏–ª–∏ Excel —Å —Ü–µ–Ω–∞–º–∏", type=["csv", "xlsx"])

st.subheader("üìà –ü—Ä–æ–≥–Ω–æ–∑ –ø–æ –≤—Å–µ–º –¥–∞–Ω–Ω—ã–º")

if uploaded_file:
    df = pd.read_excel(uploaded_file) if uploaded_file.name.endswith("xlsx") else pd.read_csv(uploaded_file)
    df.columns = ['date', 'price']
    df['date'] = pd.to_datetime(df['date'])
    df = df.set_index('date').sort_index()
    st.write(df.tail())

    try:
        scaled = scaler.transform(df[['price']])
    except:
        st.error("‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–∏. –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —Ñ–æ—Ä–º–∞—Ç 'price' –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π.")
        st.stop()

    X, y = create_dataset(scaled)
    X = X.reshape((X.shape[0], X.shape[1], 1))

    if model:
        if st.button("–°–¥–µ–ª–∞—Ç—å –ø—Ä–æ–≥–Ω–æ–∑"):
            y_pred = model.predict(X)
            y_pred_inv = scaler.inverse_transform(y_pred)
            y_true_inv = scaler.inverse_transform(y.reshape(-1, 1))
            rmse, mape, r2 = calculate_metrics(y_true_inv, y_pred_inv)
            st.success(f"üìå RMSE: {rmse:.2f} | MAPE: {mape:.3f} | R¬≤: {r2:.2f}")
            st.pyplot(plot_predictions(y_true_inv, y_pred_inv))
else:
    st.info("–ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∞.")
