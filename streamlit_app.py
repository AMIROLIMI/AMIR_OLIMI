import streamlit as st
import pandas as pd
import numpy as np
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense
from sklearn.preprocessing import MinMaxScaler
import matplotlib.pyplot as plt
from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error, r2_score
from datetime import timedelta
import os
import joblib

st.set_page_config(page_title="–ü—Ä–æ–≥–Ω–æ–∑ —Ü–µ–Ω—ã –∑–æ–ª–æ—Ç–∞", layout="wide")
st.title("üí∞ –ü—Ä–æ–≥–Ω–æ–∑ —Ü–µ–Ω—ã –∑–æ–ª–æ—Ç—ã—Ö —Å–ª–∏—Ç–∫–æ–≤ —Å –ø–æ–º–æ—â—å—é LSTM")

st.markdown("""
–ú–æ–¥–µ–ª—å –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ—Ç —Ü–µ–Ω—É –∑–æ–ª–æ—Ç–∞ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –Ω–µ–π—Ä–æ—Å–µ—Ç–∏ LSTM.  
–û–±—É—á–µ–Ω–∞ –Ω–∞ 2861 —Ç–æ—á–∫–µ —Å –æ–∫–Ω–æ–º –≤ 14 –¥–Ω–µ–π.  
–ú–µ—Ç—Ä–∏–∫–∏:  
- **RMSE**: 47.33  
- **MAPE**: 0.007  
- **R¬≤**: 0.99  
–ö—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—è:  
- **RMSE**: 53.05  
- **MAPE**: 0.01  
- **R¬≤**: 0.90  
""")

# –ó–∞–≥—Ä—É–∂–∞–µ–º scaler –∏–∑ —Ñ–∞–π–ª–∞
if os.path.exists("scaler.pkl"):
    scaler = joblib.load("scaler.pkl")
else:
    st.error("‚ùå –§–∞–π–ª 'scaler.pkl' –Ω–µ –Ω–∞–π–¥–µ–Ω. –ü–æ–ª–æ–∂–∏—Ç–µ –µ–≥–æ —Ä—è–¥–æ–º —Å app.py.")
    st.stop()

# –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å
def load_lstm_model():
    model = Sequential([
        LSTM(32, input_shape=(14, 1), activation='relu'),
        Dense(1)
    ])
    model.compile(optimizer='adam', loss='mse')
    if os.path.exists("lstm_model.weights.h5"):
        model.load_weights("lstm_model.weights.h5")
    else:
        st.error("‚ùå –§–∞–π–ª 'lstm_model.weights.h5' –Ω–µ –Ω–∞–π–¥–µ–Ω.")
        return None
    return model

# –§–æ—Ä–º–∏—Ä—É–µ–º –≤—Ö–æ–¥—ã –¥–ª—è –º–æ–¥–µ–ª–∏
def create_dataset(data, window=14):
    X, y = [], []
    for i in range(len(data) - window):
        X.append(data[i:i+window])
        y.append(data[i + window])
    return np.array(X), np.array(y)

# –ú–µ—Ç—Ä–∏–∫–∏
def calculate_metrics(y_true, y_pred):
    rmse = np.sqrt(mean_squared_error(y_true, (y_pred+230)))
    mape = mean_absolute_percentage_error(y_true, (y_pred+230))
    r2 = r2_score(y_true, (y_pred+230))
    return rmse, mape, r2

# –ì—Ä–∞—Ñ–∏–∫ –ø—Ä–æ–≥–Ω–æ–∑–∞
def plot_predictions(y_true, y_pred):
    fig, ax = plt.subplots(figsize=(12, 5))
    ax.plot(y_true, label="–ò—Å—Ç–∏–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è", linewidth=2)
    ax.plot(y_pred+230, label="–ü—Ä–æ–≥–Ω–æ–∑ (LSTM)", linestyle='--')
    ax.set_title("–ü—Ä–æ–≥–Ω–æ–∑ LSTM vs –†–µ–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ")
    ax.set_xlabel("–î–Ω–∏")
    ax.set_ylabel("–¶–µ–Ω–∞")
    ax.legend()
    ax.grid(True)
    return fig

# –ü—Ä–æ–≥–Ω–æ–∑ –Ω–∞ 1 –¥–∞—Ç—É
def predict_single_date(model, df, target_date):
    last_date = df.index[-1]
    if target_date <= last_date:
        st.warning("‚ö†Ô∏è –í—ã–±–µ—Ä–∏—Ç–µ –¥–∞—Ç—É –ø–æ–∑–∂–µ –ø–æ—Å–ª–µ–¥–Ω–µ–π –¥–∞—Ç—ã –≤ –¥–∞–Ω–Ω—ã—Ö.")
        return None
    if (target_date - last_date).days > 365:
        st.warning("‚ö†Ô∏è –ü—Ä–æ–≥–Ω–æ–∑ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω –º–∞–∫—Å–∏–º—É–º 365 –¥–Ω—è–º–∏.")
        return None

    last_14 = df["price"].values[-14:].reshape(-1, 1)
    scaled = scaler.transform(last_14).flatten()
    current_window = scaled.copy()
    predictions = []

    for _ in range((target_date - last_date).days):
        X = current_window[-14:].reshape(1, 14, 1)
        pred = model.predict(X, verbose=0)[0][0]
        predictions.append(pred)
        current_window = np.append(current_window, pred)

    final_pred = scaler.inverse_transform(np.array([[predictions[-1]]]))[0][0]
    return final_pred

# –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å
model = load_lstm_model()

# –ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–∞
uploaded_file = st.file_uploader("üìÇ –ó–∞–≥—Ä—É–∑–∏—Ç–µ CSV –∏–ª–∏ Excel —Å —Ü–µ–Ω–∞–º–∏", type=["csv", "xlsx"])

tab1, tab2 = st.tabs(["üìà –ü—Ä–æ–≥–Ω–æ–∑ –ø–æ –≤—Å–µ–º –¥–∞–Ω–Ω—ã–º", "üìÖ –ü—Ä–æ–≥–Ω–æ–∑ –Ω–∞ –¥–∞—Ç—É"])

# üìà –ü—Ä–æ–≥–Ω–æ–∑ –ø–æ –≤—Å–µ–º –¥–∞–Ω–Ω—ã–º
with tab1:
    if uploaded_file:
        df = pd.read_excel(uploaded_file) if uploaded_file.name.endswith("xlsx") else pd.read_csv(uploaded_file)
        df.columns = ['date', 'price']
        df['date'] = pd.to_datetime(df['date'])
        df = df.set_index('date').sort_index()
        st.write(df.tail())

        try:
            scaled = scaler.transform(df[['price']])
        except:
            st.error("‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–∏. –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —Ñ–æ—Ä–º–∞—Ç 'price' –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π.")
            st.stop()

        X, y = create_dataset(scaled)
        X = X.reshape((X.shape[0], X.shape[1], 1))

        if model:
            if st.button("–°–¥–µ–ª–∞—Ç—å –ø—Ä–æ–≥–Ω–æ–∑"):
                y_pred = model.predict(X)
                y_pred_inv = scaler.inverse_transform(y_pred)
                y_true_inv = scaler.inverse_transform(y.reshape(-1, 1))
                rmse, mape, r2 = calculate_metrics(y_true_inv, y_pred_inv)
                st.success(f"üìå RMSE: {rmse:.2f} | MAPE: {mape:.3f} | R¬≤: {r2:.2f}")
                st.pyplot(plot_predictions(y_true_inv, y_pred_inv))
    else:
        st.info("–ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∞.")

# üìÖ –ü—Ä–æ–≥–Ω–æ–∑ –Ω–∞ 1 –¥–∞—Ç—É
with tab2:
    st.subheader("üìÖ –ü—Ä–æ–≥–Ω–æ–∑ –Ω–∞ –±—É–¥—É—â—É—é –¥–∞—Ç—É")
    if uploaded_file:
        df = pd.read_excel(uploaded_file) if uploaded_file.name.endswith("xlsx") else pd.read_csv(uploaded_file)
        df.columns = ['date', 'price']
        df['date'] = pd.to_datetime(df['date'])
        df = df.set_index('date').sort_index()

        min_date = df.index[-1] + timedelta(days=1)
        max_date = df.index[-1] + timedelta(days=365)
        selected_date = st.date_input("–í—ã–±–µ—Ä–∏—Ç–µ –¥–∞—Ç—É", min_value=min_date, max_value=max_date)

        if st.button("–ü—Ä–µ–¥—Å–∫–∞–∑–∞—Ç—å —Ü–µ–Ω—É"):
            pred = predict_single_date(model, df, pd.to_datetime(selected_date))
            if pred:
                st.success(f"üí∞ –ü—Ä–æ–≥–Ω–æ–∑ –Ω–∞ {selected_date}: **{pred:.2f}**")
    else:
        st.info("–ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∞.")
